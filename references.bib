@online{PewResearchMobileFactSheet2024,
  title        = {Mobile Fact Sheet},
  description  = {Fact Sheets: Tech Adoption Trends},
  organization = {Pew Research Center},
  year         = {2024},
  url          = {https://www.pewresearch.org/internet/fact-sheet/mobile/},
  lastaccessed = {January 07, 2025}
}

@online{FortuneBusinessInsights2024,
  number       = {FBI100307},
  title        = {Internet of Things [IoT] Market Size, Share, Growth, Trends, 2032},
  organization = {Fortune Business Insights},
  year         = {2024},
  url          = {https://www.fortunebusinessinsights.com/industry-reports/internet-of-things-iot-market-100307},
  lastaccessed = {January 07, 2025}
}

@online{DeloitteConnectedConsumer2023,
  title        = {Deloitte: The Connected Consumer Paradox - Desire for Fewer Devices vs. More Virtual Experiences and Technology Innovation},
  organization = {PRNewswire},
  year         = {2023},
  url          = {https://www.prnewswire.com/news-releases/deloitte-the-connected-consumer-paradox---desire-for-fewer-devices-vs-more-virtual-experiences-and-technology-innovation-301919928.html},
  lastaccessed = {January 07, 2025}
}

@inproceedings{Gyrophone2014,
  author    = {Michalevsky, Yan and Boneh, Dan and Nakibly, Gabi},
  title     = {Gyrophone: recognizing speech from gyroscope signals},
  year      = {2014},
  isbn      = {9781931971157},
  publisher = {USENIX Association},
  address   = {USA},
  abstract  = {We show that the MEMS gyroscopes found on modern smart phones are sufficiently sensitive to measure acoustic signals in the vicinity of the phone. The resulting signals contain only very low-frequency information (<200Hz). Nevertheless we show, using signal processing and machine learning, that this information is sufficient to identify speaker information and even parse speech. Since iOS and Android require no special permissions to access the gyro, our results show that apps and active web content that cannot access the microphone can nevertheless eavesdrop on speech in the vicinity of the phone.},
  booktitle = {Proceedings of the 23rd USENIX Conference on Security Symposium},
  pages     = {1053–1067},
  numpages  = {15},
  location  = {San Diego, CA},
  series    = {SEC'14}
}

@inproceedings{PitchIn2017,
  author    = {Han, Jun and Chung, Albert Jin and Tague, Patrick},
  title     = {PitchIn: eavesdropping via intelligible speech reconstruction using non-acoustic sensor fusion},
  year      = {2017},
  isbn      = {9781450348904},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3055031.3055088},
  doi       = {10.1145/3055031.3055088},
  abstract  = {Despite the advent of numerous Internet-of-Things (IoT) applications, recent research demonstrates potential side-channel vulnerabilities exploiting sensors which are used for event and environment monitoring. In this paper, we propose a new side-channel attack, where a network of distributed non-acoustic sensors can be exploited by an attacker to launch an eavesdropping attack by reconstructing intelligible speech signals. Specifically, we present PitchIn to demonstrate the feasibility of speech reconstruction from non-acoustic sensor data collected offline across networked devices. Unlike speech reconstruction which requires a high sampling frequency (e.g., > 5 KHz), typical applications using non-acoustic sensors do not rely on richly sampled data, presenting a challenge to the speech reconstruction attack. Hence, PitchIn leverages a distributed form of Time Interleaved Analog-Digital-Conversion (TIADC) to approximate a high sampling frequency, while maintaining low per-node sampling frequency. We demonstrate how distributed TI-ADC can be used to achieve intelligibility by processing an interleaved signal composed of different sensors across networked devices. We implement PitchIn and evaluate reconstructed speech signal intelligibility via user studies. PitchIn has word recognition accuracy as high as 79\%. Though some additional work is required to improve accuracy, our results suggest that eavesdropping using a fusion of non-acoustic sensors is a real and practical threat.},
  booktitle = {Proceedings of the 16th ACM/IEEE International Conference on Information Processing in Sensor Networks},
  pages     = {181–192},
  numpages  = {12},
  keywords  = {non-acoustic sensors, privacy, security, sensor fusion, speech reconstruction},
  location  = {Pittsburgh, Pennsylvania},
  series    = {IPSN '17}
}

@inproceedings{AccelEve2020,
  author = {Ba, Zhongjie and Zheng, Tianhang and Zhang, Xinyu and Qin, Zhan and Li, Baochun and Liu, Xue and Ren, Kui},
  year   = {2020},
  month  = {01},
  pages  = {},
  title  = {Learning-based Practical Smartphone Eavesdropping with Built-in Accelerometer},
  doi    = {10.14722/ndss.2020.24076}
}

@inproceedings{Spearphone2021,
  author    = {Anand, S Abhishek and Wang, Chen and Liu, Jian and Saxena, Nitesh and Chen, Yingying},
  title     = {Spearphone: a lightweight speech privacy exploit via accelerometer-sensed reverberations from smartphone loudspeakers},
  year      = {2021},
  isbn      = {9781450383493},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3448300.3468499},
  doi       = {10.1145/3448300.3468499},
  abstract  = {In this paper, we build a speech privacy attack that exploits speech reverberations from a smartphone's inbuilt loudspeaker captured via a zero-permission motion sensor (accelerometer). We design our attack Spearphone, and demonstrate that speech reverberations from inbuilt loudspeakers, at an appropriate loudness, can impact the accelerometer, leaking sensitive information about the speech. In particular, we show that by exploiting the affected accelerometer readings and carefully selecting feature sets along with off-the-shelf machine learning techniques, Spearphone can perform gender classification (accuracy over 90\%) and speaker identification (accuracy over 80\%) for the audio/video playback on the smartphone for our recorded dataset. We use lightweight classifiers and an off-the-shelf machine learning tool so that the attacking effort is minimized, making our attack practical. Our results with testing the attack on a voice call and voice assistant response were also encouraging, showcasing the impact of the proposed attack. In addition, we perform speech recognition and speech reconstruction to extract more information about the eavesdropped speech to an extent. Our work brings to light a fundamental design vulnerability in many currently-deployed smartphones, which may put people's speech privacy at risk while using the smartphone in the loudspeaker mode during phone calls, media playback or voice assistant interactions.},
  booktitle = {Proceedings of the 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
  pages     = {288–299},
  numpages  = {12},
  keywords  = {motion sensors, side channel, speech privacy},
  location  = {Abu Dhabi, United Arab Emirates},
  series    = {WiSec '21}
}

@article{ISpyU2023,
  author     = {Zhang, Shijia and Liu, Yilin and Gowda, Mahanth},
  title      = {I Spy You: Eavesdropping Continuous Speech on Smartphones via Motion Sensors},
  year       = {2023},
  issue_date = {December 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {6},
  number     = {4},
  url        = {https://doi.org/10.1145/3569486},
  doi        = {10.1145/3569486},
  abstract   = {This paper presents iSpyU, a system that shows the feasibility of recognition of natural speech content played on a phone during conference calls (Skype, Zoom, etc) using a fusion of motion sensors such as accelerometer and gyroscope. While microphones require permissions from the user to be accessible by an app developer, the motion sensors are zero-permission sensors, thus accessible by a developer without alerting the user. This allows a malicious app to potentially eavesdrop on sensitive speech content played by the user's phone. In designing the attack, iSpyU tackles a number of technical challenges including: (i) Low sampling rate of motion sensors (500 Hz in comparison to 44 kHz for a microphone). (ii) Lack of availability of large-scale training datasets to train models for Automatic Speech Recognition (ASR) with motion sensors. iSpyU systematically addresses these challenges by a combination of techniques in synthetic training data generation, ASR modeling, and domain adaptation. Extensive measurement studies on modern smartphones show a word level accuracy of 53.3 - 59.9\% over a dictionary of 2000-10000 words, and a character level accuracy of 70.0 - 74.8\%. We believe such levels of accuracy poses a significant threat when viewed from a privacy perspective.},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  month      = jan,
  articleno  = {197},
  numpages   = {31},
  keywords   = {IoT Security, Speech Privacy}
}

@article{KineticSongComprehension2019,
  author     = {Richard Matovu and
                Isaac Griswold{-}Steiner and
                Abdul Serwadda},
  title      = {Kinetic Song Comprehension: Deciphering Personal Listening Habits
                via Phone Vibrations},
  journal    = {CoRR},
  volume     = {abs/1909.09123},
  year       = {2019},
  url        = {http://arxiv.org/abs/1909.09123},
  eprinttype = {arXiv},
  eprint     = {1909.09123},
  timestamp  = {Tue, 24 Sep 2019 11:33:51 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1909-09123.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{AccelWorld2015,
  author    = {Zhang, Li and Pathak, Parth H. and Wu, Muchen and Zhao, Yixin and Mohapatra, Prasant},
  title     = {AccelWord: Energy Efficient Hotword Detection through Accelerometer},
  year      = {2015},
  isbn      = {9781450334945},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2742647.2742658},
  doi       = {10.1145/2742647.2742658},
  abstract  = {Voice control has emerged as a popular method for interacting with smart-devices such as smartphones, smartwatches etc. Popular voice control applications like Siri and Google Now are already used by a large number of smartphone and tablet users. A major challenge in designing a voice control application is that it requires continuous monitoring of user?s voice input through the microphone. Such applications utilize hotwords such as "Okay Google" or "Hi Galaxy" allowing them to distinguish user?s voice command and her other conversations. A voice control application has to continuously listen for hotwords which significantly increases the energy consumption of the smart-devices.To address this energy efficiency problem of voice control, we present AccelWord in this paper. AccelWord is based on the empirical evidence that accelerometer sensors found in today?s mobile devices are sensitive to user?s voice. We also demonstrate that the effect of user?s voice on accelerometer data is rich enough so that it can be used to detect the hotwords spoken by the user. To achieve the goal of low energy cost but high detection accuracy, we combat multiple challenges, e.g. how to extract unique signatures of user?s speaking hotwords only from accelerometer data and how to reduce the interference caused by user?s mobility.We finally implement AccelWord as a standalone application running on Android devices. Comprehensive tests show AccelWord has hotword detection accuracy of 85\% in static scenarios and 80\% in mobile scenarios. Compared to the microphone based hotword detection applications such as Google Now and Samsung S Voice, AccelWord is 2 times more energy efficient while achieving the accuracy of 98\% and 92\% in static and mobile scenarios respectively.},
  booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
  pages     = {301–315},
  numpages  = {15},
  keywords  = {measurement, hotword detection, energy, accelword, accelerometer},
  location  = {Florence, Italy},
  series    = {MobiSys '15}
}

@inproceedings{Speechless2018,
  author    = {Anand, S Abhishek and Saxena, Nitesh},
  booktitle = {2018 IEEE Symposium on Security and Privacy (SP)},
  title     = {Speechless: Analyzing the Threat to Speech Privacy from Smartphone Motion Sensors},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {1000-1017},
  keywords  = {Sensors;Privacy;Vibrations;Accelerometers;Portable computers;Loudspeakers;Gyroscopes;side-channel attacks;motion sensors;speech privacy},
  doi       = {10.1109/SP.2018.00004}
}

@inproceedings{WatchTheRhythm2024,
  author    = {Yao, Qingsong and Liu, Yuming and Sun, Xiongjia and Dong, Xuewen and Ji, Xiaoyu and Ma, Jianfeng},
  title     = {Watch the Rhythm: Breaking Privacy with Accelerometer at the Extremely-Low Sampling Rate of 5Hz},
  year      = {2024},
  isbn      = {9798400706363},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3658644.3690370},
  doi       = {10.1145/3658644.3690370},
  abstract  = {Considering the threat from on-board eavesdropping with smartphone motion sensors, Android 12 has limited the maximum sampling rate of motion sensors to 200Hz for zero-privilege access to prevent potential wiretapping. Unfortunately, there have been some attacks targeting 200Hz, making it not a safe sampling rate any more. Smartphone manufacturers may further reduce the maximum sampling rate of the accelerometer in response to this privacy concern. It can be expected that, the maximum sampling rate will gradually decrease to a very low level, as the battle between manufacturers and adversaries continues. Existing on-board eavesdropping approaches, utilizing spectral features, cannot provide acceptable accuracy at very low sampling rates, not even at 50Hz.Therefore, this paper explores the feasibility of using the on-board accelerometer for privacy breaking with an extremely-low sampling rate, specifically, 5Hz. 5Hz is a minimum sampling rate to meet normal use, otherwise the applications can only choose to work without the accelerometer. Since the lowest fundamental frequency for humans is around 85Hz, such a low sampling rate poses a significant challenge for sound recognition. According to Nyquist's law, it seems impossible to capture 85Hz with the sampling rate of 5Hz. Fortunately, we observe that the rhythm features, including pause rhythm and intensity rhythm, of accelerometer data are relatively stable at various sampling rates. On this basis, we propose an eavesdropping approach with the accelerometer at an extremely-low sampling rate. Introducing the rhythm features, we achieve an accuracy of 95.09\% at 50Hz and 78.66\% at 5Hz for scene recognition. The accuracy is 90.60\% at 50Hz and 47\% at 5Hz for Chinese digits recognition, plus 96.63\% at 50Hz and 58.67\% at 5Hz for popular Chinese cities recognition. Furthermore, we achieve determination for typical places like bar, metro, bus, car, and quiet room, by analyzing the vibration of surroundings, with an average accuracy of 91.28\%. Combining place determination with eavesdropping, our approach poses a serious threat to personal privacy. Since 5Hz is generally used for screen orientation detection, our attack can hide in any kind of application, not just in game or sport applications. We also suggest some countermeasures.},
  booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
  pages     = {1776–1790},
  numpages  = {15},
  keywords  = {extremely-low sampling rate, on-board eavesdropping, rhythm features, side-channel attack},
  location  = {Salt Lake City, UT, USA},
  series    = {CCS '24}
}

@article{AccMyrinx2022,
  author     = {Liang, Yunji and Qin, Yuchen and Li, Qi and Yan, Xiaokai and Yu, Zhiwen and Guo, Bin and Samtani, Sagar and Zhang, Yanyong},
  title      = {AccMyrinx: Speech Synthesis with Non-Acoustic Sensor},
  year       = {2022},
  issue_date = {September 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {6},
  number     = {3},
  url        = {https://doi.org/10.1145/3550338},
  doi        = {10.1145/3550338},
  abstract   = {The built-in loudspeakers of mobile devices (e.g., smartphones, smartwatches, and tablets) play significant roles in human-machine interaction, such as playing music, making phone calls, and enabling voice-based interaction. Prior studies have pointed out that it is feasible to eavesdrop on the speaker via motion sensors, but whether it is possible to synthesize speech from non-acoustic signals with sub-Nyquist sampling frequency has not been studied. In this paper, we present an end-to-end model to reconstruct the acoustic waveforms that are playing on the loudspeaker through the vibration captured by the built-in accelerometer. Specifically, we present an end-to-end speech synthesis framework dubbed AccMyrinx to eavesdrop on the speaker using the built-in low-resolution accelerometer of mobile devices. AccMyrinx takes advantage of the coexistence of an accelerometer with the loudspeaker on the same motherboard and compromises the loudspeaker by the solid-borne vibrations captured by the accelerometer. Low-resolution vibration signals are fed to a wavelet-based MelGAN to generate intelligible acoustic waveforms. We conducted extensive experiments on a large-scale dataset created based on audio clips downloaded from Voice of America (VOA). The experimental results show that AccMyrinx is capable of reconstructing intelligible acoustic signals that are playing on the loudspeaker with a smoothed word error rate (SWER) of 42.67\%. The quality of synthesized speeches could be severely affected by several factors including gender, speech rate, and volume.},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  month      = sep,
  articleno  = {127},
  numpages   = {24},
  keywords   = {accelerometer, generative adversary network, non-acoustic sensor, speaker, speech synthesis}
}

@article{Vibphone2021,
  author     = {Su, Weigao and Liu, Daibo and Zhang, Taiyuan and Jiang, Hongbo},
  title      = {Towards Device Independent Eavesdropping on Telephone Conversations with Built-in Accelerometer},
  year       = {2022},
  issue_date = {Dec 2021},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {5},
  number     = {4},
  url        = {https://doi.org/10.1145/3494969},
  doi        = {10.1145/3494969},
  abstract   = {Motion sensors in modern smartphones have been exploited for audio eavesdropping in loudspeaker mode due to their sensitivity to vibrations. In this paper, we further move one step forward to explore the feasibility of using built-in accelerometer to eavesdrop on the telephone conversation of caller/callee who takes the phone against cheek-ear and design our attack Vibphone. The inspiration behind Vibphone is that the speech-induced vibrations (SIV) can be transmitted through the physical contact of phone-cheek to accelerometer with the traces of voice content. To this end, Vibphone faces three main challenges: i) Accurately detecting SIV signals from miscellaneous disturbance; ii) Combating the impact of device diversity to work with a variety of attack scenarios; and iii) Enhancing feature-agnostic recognition model to generalize to newly issued devices and reduce training overhead. To address these challenges, we first conduct an in-depth investigation on SIV features to figure out the root cause of device diversity impacts and identify a set of critical features that are highly relevant to the voice content retained in SIV signals and independent of specific devices. On top of these pivotal observations, we propose a combo method that is the integration of extracted critical features and deep neural network to recognize speech information from the spectrogram representation of acceleration signals. We implement the attack using commodity smartphones and the results show it is highly effective. Our work brings to light a fundamental design vulnerability in the vast majority of currently deployed smartphones, which may put people's speech privacy at risk during phone calls. We also propose a practical and effective defense solution. We validate that it is feasible to prevent audio eavesdropping by using random variation of sampling rate.},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  month      = dec,
  articleno  = {177},
  numpages   = {29},
  keywords   = {Vibration Recognition, Smartphone Conversation Eavesdropping, Privacy Attack}
}

@article{VoiceListener2023,
  author     = {Wang, Lei and Chen, Meng and Lu, Li and Ba, Zhongjie and Lin, Feng and Ren, Kui},
  title      = {VoiceListener: A Training-free and Universal Eavesdropping Attack on Built-in Speakers of Mobile Devices},
  year       = {2023},
  issue_date = {March 2023},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {7},
  number     = {1},
  url        = {https://doi.org/10.1145/3580789},
  doi        = {10.1145/3580789},
  abstract   = {Recently, voice leakage gradually raises more significant concerns of users, due to its underlying sensitive and private information when providing intelligent services. Existing studies demonstrate the feasibility of applying learning-based solutions on built-in sensor measurements to recover voices. However, due to the privacy concerns, large-scale voices-sensor measurements samples for model training are not publicly available, leading to significant efforts in data collection for such an attack. In this paper, we propose a training-free and universal eavesdropping attack on built-in speakers, VoiceListener, which releases the data collection efforts and is able to adapt to various voices, platforms, and domains. In particular, VoiceListener develops an aliasing-corrected super resolution mechanism, including an aliasing-based pitch estimation and an aliasing-corrected voice recovering, to convert the undersampled narrow-band sensor measurements to wide-band voices. Extensive experiments demonstrate that our proposed VoiceListener could accurately recover the voices from undersampled sensor measurements and is robust to different voices, platforms and domains, realizing the universal eavesdropping attack.},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  month      = mar,
  articleno  = {32},
  numpages   = {22},
  keywords   = {Eavesdropping, aliasing correction, speakers, super resolution}
}

@inproceedings{LidarPhone2020,
  author    = {Sami, Sriram and Tan, Sean Rui Xiang and Dai, Yimin and Roy, Nirupam and Han, Jun},
  title     = {LidarPhone: acoustic eavesdropping using a lidar sensor: poster abstract},
  year      = {2020},
  isbn      = {9781450375900},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3384419.3430430},
  doi       = {10.1145/3384419.3430430},
  abstract  = {Private conversations are an attractive target for malicious actors intending to conduct audio eavesdropping attacks. Previous works discovered unexpected vectors for these attacks, such as analyzing high-speed video of objects adjacent to sound sources, or using WiFi signal information. We propose LidarPhone, a novel side-channel attack that exploits the lidar sensors in commodity robot vacuum cleaners to perform acoustic eavesdropping attacks. LidarPhone is able to detect the minute vibrations induced on objects that are near audio sources, and extract meaningful signals from inherently noisy raw lidar returns. We evaluate a realistic scenario for potential victims: recovering privacy-sensitive digits (e.g., credit card numbers, social security numbers) emitted by computer speakers during teleconferencing calls. We implement LidarPhone on a Xiaomi Roborock vacuum cleaning robot and perform a comprehensive series of real-world experiments to determine its performance. LidarPhone achieves up to 91\% accuracy for digit classification.},
  booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
  pages     = {701–702},
  numpages  = {2},
  keywords  = {acoustic side-channel, eavesdropping, lidar},
  location  = {Virtual Event, Japan},
  series    = {SenSys '20}
}

@inproceedings{HardDriveOfHearing2019,
  author    = {Kwong, Andrew and Xu, Wenyuan and Fu, Kevin},
  booktitle = {2019 IEEE Symposium on Security and Privacy (SP)},
  title     = {Hard Drive of Hearing: Disks that Eavesdrop with a Synthesized Microphone},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {905-919},
  keywords  = {Microphones;Acoustics;Magnetic heads;Hard disks;Malware;Sensors;Drives;embedded-security;side-channels;acoustics;hard-drives},
  doi       = {10.1109/SP.2019.00008}
}

@inproceedings{Touchtone2023,
  author    = {Bolton, Connor and Long, Yan and Han, Jun and Hester, Josiah and Fu, Kevin},
  title     = {Characterizing and Mitigating Touchtone Eavesdropping in Smartphone Motion Sensors},
  year      = {2023},
  isbn      = {9798400707650},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3607199.3607203},
  doi       = {10.1145/3607199.3607203},
  abstract  = {Smartphone motion sensors provide cybersecurity attackers with a stealthy way to eavesdrop on nearby acoustic information. Eavesdropping on touchtones emitted by smartphone speakers when users input numbers into their phones exposes sensitive information such as credit card information, banking PINs, and social security card numbers to malicious applications with access to only motion sensor data. This work characterizes this new security threat of touchtone eavesdropping by providing an analysis based on physics and signal processing theory. We show that advanced adversaries who selectively integrate data from multiple motion sensors and multiple sensor axes can achieve over 99\% accuracy on recognizing 12 unique touchtones. We further design, analyze, and evaluate several mitigations which could be implemented in a smartphone update. We found that some apparent mitigations such as low-pass filters can undesirably reduce the motion sensor data to benign applications by 83\% but only reduce an advanced adversary’s accuracy by less than one percent. Other more informed designs such as anti-aliasing filters can fully preserve the motion sensor data to support benign application functionality while reducing attack accuracy by 50.1\%.},
  booktitle = {Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses},
  pages     = {164–178},
  numpages  = {15},
  keywords  = {DTMF, eavesdropping, motion sensor, smartphone, touchtone},
  location  = {Hong Kong, China},
  series    = {RAID '23}
}

@inproceedings{TouchLogger2011,
  author    = {Cai, Liang and Chen, Hao},
  title     = {TouchLogger: inferring keystrokes on touch screen from smartphone motion},
  year      = {2011},
  publisher = {USENIX Association},
  address   = {USA},
  abstract  = {Attacks that use side channels, such as sound and electromagnetic emanation, to infer keystrokes on physical keyboards are ineffective on smartphones without physical keyboards. We describe a new side channel, motion, on touch screen smartphones with only soft keyboards. Since typing on different locations on the screen causes different vibrations, motion data can be used to infer the keys being typed. To demonstrate this attack, we developed TouchLogger, an Android application that extracts features from device orientation data to infer keystrokes. TouchLogger correctly inferred more than 70\% of the keys typed on a number-only soft keyboard on a smartphone. We hope to raise the awareness of motion as a significant side channel that may leak confidential data.},
  booktitle = {Proceedings of the 6th USENIX Conference on Hot Topics in Security},
  pages     = {9},
  numpages  = {1},
  location  = {San Francisco, CA},
  series    = {HotSec'11}
}

@inproceedings{TapLogger2012,
  author    = {Xu, Zhi and Bai, Kun and Zhu, Sencun},
  title     = {TapLogger: inferring user inputs on smartphone touchscreens using on-board motion sensors},
  year      = {2012},
  isbn      = {9781450312653},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2185448.2185465},
  doi       = {10.1145/2185448.2185465},
  abstract  = {Today's smartphones are shipped with various embedded motion sensors, such as the accelerometer, gyroscope, and orientation sensors. These motion sensors are useful in supporting the mobile UI innovation and motion-based commands. However, they also bring potential risks of leaking user's private information as they allow third party applications to monitor the motion changes of smartphones.In this paper, we study the feasibility of inferring a user's tap inputs to a smartphone with its integrated motion sensors. Specifically, we utilize an installed trojan application to stealthily monitor the movement and gesture changes of a smartphone using its on-board motion sensors. When the user is interacting with the trojan application, it learns the motion change patterns of tap events. Later, when the user is performing sensitive inputs, such as entering passwords on the touchscreen, the trojan application applies the learnt pattern to infer the occurrence of tap events on the touchscreen as well as the tapped positions on the touchscreen.For demonstration, we present the design and implementation of TapLogger, a trojan application for the Android platform, which stealthily logs the password of screen lock and the numbers entered during a phone call (e.g., credit card and PIN numbers). Statistical results are presented to show the feasibility of such inferences and attacks.},
  booktitle = {Proceedings of the Fifth ACM Conference on Security and Privacy in Wireless and Mobile Networks},
  pages     = {113–124},
  numpages  = {12},
  keywords  = {accelerometer sensor, android, motion sensor, orientation sensor, smartphone, trojan, user inputs logger},
  location  = {Tucson, Arizona, USA},
  series    = {WISEC '12}
}

@inproceedings{ART2015,
  author    = {Wei, Teng and Wang, Shu and Zhou, Anfu and Zhang, Xinyu},
  title     = {Acoustic Eavesdropping through Wireless Vibrometry},
  year      = {2015},
  isbn      = {9781450336192},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2789168.2790119},
  doi       = {10.1145/2789168.2790119},
  abstract  = {Loudspeakers are widely used in conferencing and infotainment systems. Private information leakage from loudspeaker sound is often assumed to be preventable using sound-proof isolators like walls. In this paper, we explore a new acoustic eavesdropping attack that can subvert such protectors using radio devices. Our basic idea lies in an acoustic-radio transformation (ART) algorithm, which recovers loudspeaker sound by inspecting the subtle disturbance it causes to the radio signals generated by an adversary or by its co-located WiFi transmitter. ART builds on a modeling framework that distills key factors to determine the recovered audio quality. It incorporates diversity mechanisms and noise suppression algorithms that can boost the eavesdropping quality. We implement the ART eavesdropper on a software-radio platform and conduct experiments to verify its feasibility and threat level. When targeted at vanilla PC or smartphone loudspeakers, the attacker can successfully recover high-quality audio even when blocked by sound-proof walls. On the other hand, we propose several pragmatic countermeasures that can effectively reduce the attacker's audio recovery quality by orders of magnitude.},
  booktitle = {Proceedings of the 21st Annual International Conference on Mobile Computing and Networking},
  pages     = {130–141},
  numpages  = {12},
  keywords  = {acoustic eavesdropping, acoustic-radio transformation, wifi devices},
  location  = {Paris, France},
  series    = {MobiCom '15}
}

@inproceedings{MMMic2022,
  author    = {Chen, Wei-Han and Srinivasan, Kannan},
  booktitle = {GLOBECOM 2022 - 2022 IEEE Global Communications Conference},
  title     = {Acoustic Eavesdropping from Passive Vibrations via mmWave Signals},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {4051-4056},
  keywords  = {Vibrations;Wireless communication;Millimeter wave technology;Vibration measurement;Signal processing;Acoustics;Real-time systems;mmWave;eavesdropping;vibrometry},
  doi       = {10.1109/GLOBECOM48099.2022.10001108}
}

@article{RFMic2023,
  author     = {Chen, Yunzhong and Yu, Jiadi and Kong, Linghe and Kong, Hao and Zhu, Yanmin and Chen, Yi-Chao},
  title      = {RF-Mic: Live Voice Eavesdropping via Capturing Subtle Facial Speech Dynamics Leveraging RFID},
  year       = {2023},
  issue_date = {June 2023},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {7},
  number     = {2},
  url        = {https://doi.org/10.1145/3596259},
  doi        = {10.1145/3596259},
  abstract   = {Eavesdropping on human voice is one of the most common but harmful threats to personal privacy. Glasses are in direct contact with human face, which could sense facial motions when users speak, so human speech contents could be inferred by sensing the movements of glasses. In this paper, we present a live voice eavesdropping method, RF-Mic, which utilizes common glasses attached with a low-cost RFID tag to sense subtle facial speech dynamics for inferring possible voice contents. When a user with a glasses, which is attached an RFID tag on the glass bridge, is speaking, RF-Mic first collects RF signals through forward propagation and backscattering. Then, body motion interference is eliminated from the collected RF signals through a proposed Conditional Denoising AutoEncoder (CDAE) network. Next, RF-Mic extracts three kinds of facial speech dynamic features (i.e., facial movements, bone-borne vibrations, and airborne vibrations) by designing three different deep-learning models. Based on the extracted features, a facial speech dynamics model is constructed for live voice eavesdropping. Extensive experiments in different real environments demonstrate that RF-Mic can achieve robust and accurate human live voice eavesdropping.},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  month      = jun,
  articleno  = {49},
  numpages   = {25},
  keywords   = {RFID, facial dynamics, glasses, voice eavesdropping}
}

@article{InertiEAR2022,
  author  = {Gao, Ming and Liu, Yajie and Chen, Yike and Li, Yimin and Ba, Zhongjie and Xu, Xian and Han, Jinsong and Ren, Kui},
  year    = {2022},
  month   = {01},
  pages   = {1-14},
  title   = {Device-Independent Smartphone Eavesdropping Jointly Using Accelerometer and Gyroscope},
  volume  = {PP},
  journal = {IEEE Transactions on Dependable and Secure Computing},
  doi     = {10.1109/TDSC.2022.3193130}
}

@inproceedings{StealthyIMU2023,
  author = {Sun, Ke and Xia, Chunyu and Xu, Songlin and Zhang, Xinyu},
  year   = {2023},
  month  = {01},
  pages  = {},
  title  = {StealthyIMU: Stealing Permission-protected Private Information From Smartphone Voice Assistant Using Zero-Permission Sensors},
  doi    = {10.14722/ndss.2023.24077}
}

@inproceedings{HearingCheckFailed2022,
  author    = {Walker, Payton and Saini, Shalini and Anand, S. Abhishek and Halevi, Tzipora and Saxena, Nitesh},
  title     = {Hearing Check Failed: Using Laser Vibrometry to Analyze the Potential for Hard Disk Drives to Eavesdrop Speech Vibrations},
  year      = {2022},
  isbn      = {9781450391405},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3488932.3517399},
  doi       = {10.1145/3488932.3517399},
  abstract  = {Sound waves from speech can potentially induce vibrations, proportional to the speech signal, on nearby objects. Each of these objects introduces the risk for a malicious attacker to exploit the induced vibrations to eavesdrop on the speech. Such an eavesdropping attack is critical when we consider the potential for induced vibrations in standard magnetic hard disk drives (HDDs). As an instance of this threat, prior research has demonstrated that speech in certain scenarios can induce vibrations on the read/write head of an HDD in order to eavesdrop on the speech (Kwong et al.; Oakland'19). In this paper, we revisit this line of research and aim to provide a closer investigation into whether HDDs can in fact be used as a source for eavesdropping on speech vibrations. As a foundation for our study, we utilize an effective, and robust methodology using laser vibrometry to measure the subtle speech vibrations induced on the read/write head. The prior study tested only a single HDD and only machine-rendered speech in a single setting with very loud speech. Our work broadens the scope of this research in many significant ways. First, we test multiple popular HDDs of different models and sizes to evaluate the generalizability of the overall threat. Second, we evaluate the threat from live human speech spoken near an HDD, expanding the scope of the attack to include most real-world speech settings involving normal human conversations. Third, we define machine-rendered speech scenarios to explore different propagation media and degrees of speech loudness. Our findings are two-fold. First, we observed that live human speech traveling through the air is not generally strong enough to impact HDDs such that intelligible speech information is leaked. Second, most tested HDDs did not seem capable of eavesdropping on machine-rendered speech unless the speech is loud enough, or the HDD shares a surface or is in direct contact with the speaker device. This implies HDDs cannot eavesdrop live human speech.},
  booktitle = {Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security},
  pages     = {67–81},
  numpages  = {15},
  keywords  = {speech eavesdropping, side-channel attack, laser vibrometry, hard disk drives},
  location  = {Nagasaki, Japan},
  series    = {ASIA CCS '22}
}

@inproceedings{Lamphone2022,
  title     = {Lamphone: Passive Sound Recovery from a Desk Lamp's Light Bulb Vibrations},
  author    = {Ben Nassi and Yaron Pirutin and Raz Swisa and Adi Shamir and Yuval Elovici and Boris Zadov},
  booktitle = {USENIX Security Symposium},
  year      = {2022},
  url       = {https://api.semanticscholar.org/CorpusID:252402906}
}

@inproceedings{AccelerometerFingerprinting2016,
  author    = {Goethem, Tom and Scheepers, Wout and Preuveneers, Davy and Joosen, Wouter},
  title     = {Accelerometer-Based Device Fingerprinting for Multi-factor Mobile Authentication},
  year      = {2016},
  isbn      = {9783319308050},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  url       = {https://doi.org/10.1007/978-3-319-30806-7_7},
  doi       = {10.1007/978-3-319-30806-7_7},
  abstract  = {Due to the numerous data breaches, often resulting in the disclosure of a substantial amount of user passwords, the classic authentication scheme where just a password is required to log in, has become inadequate. As a result, many popular web services now employ risk-based authentication systems where various bits of information are requested in order to determine the authenticity of the authentication request. In this risk assessment process, values consisting of geo-location, IP address and browser-fingerprint information, are typically used to detect anomalies in comparison with the user's regular behavior.In this paper, we focus on risk-based authentication mechanisms in the setting of mobile devices, which are known to fall short of providing reliable device-related information that can be used in the risk analysis process. More specifically, we present a web-based and low-effort system that leverages accelerometer data generated by a mobile device for the purpose of device re-identification. Furthermore, we evaluate the performance of these techniques and assess the viability of embedding such a system as part of existing risk-based authentication processes.},
  booktitle = {Proceedings of the 8th International Symposium on Engineering Secure Software and Systems - Volume 9639},
  pages     = {106–121},
  numpages  = {16},
  location  = {London, UK},
  series    = {ESSoS 2016}
}

@inproceedings{MEMSFingerprinting2013,
  author    = {Aysu, Aydin and Ghalaty, Nahid Farhady and Franklin, Zane and Yali, Moein Pahlavan and Schaumont, Patrick},
  title     = {Digital fingerprints for low-cost platforms using MEMS sensors},
  year      = {2013},
  isbn      = {9781450321457},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2527317.2527319},
  doi       = {10.1145/2527317.2527319},
  abstract  = {With the Internet of Things on the horizon, correct authentication of Things within a population will become one of the major concerns for security. Physical authentication, which is implementing digital fingerprints by utilizing device-unique manufacturing variations, has great potential for achieving this purpose. MEMS sensors that are used in the Internet of Things have not been explored as a source of variation. In this paper, we target a commonly used MEMS sensor, an accelerometer, and utilize its process variations to generate digital fingerprints. This is achieved by measuring the accelerometer's response to an applied electrostatic impulse and its inherent offset values. Our results revealed that MEMS sensors could be used as a source for digital fingerprints for run-time authentication applications.},
  booktitle = {Proceedings of the Workshop on Embedded Systems Security},
  articleno = {2},
  numpages  = {6},
  keywords  = {physical authentication, microcontrollers, digital fingerprints, accelerometer sensor, RFID},
  location  = {Montreal, Quebec, Canada},
  series    = {WESS '13}
}

@inproceedings{SokVibration2021,
  author    = {Walker, Payton and Saxena, Nitesh},
  title     = {SoK: assessing the threat potential of vibration-based attacks against live speech using mobile sensors},
  year      = {2021},
  isbn      = {9781450383493},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3448300.3467825},
  doi       = {10.1145/3448300.3467825},
  abstract  = {Existing academic research on vibration-based speech attacks has introduced interesting and intellectually appealing threat vectors with proof-of-concept demonstrations in controlled environments. The attacks presented in these studies exploit different types of sensors such as MEMS motion sensors, laser-based sensors, and some other sensors (camera, position error signal, piezo-disc) to measure the vibrations induced on an object by nearby sensitive speech. Such sensors are commonly found on mobile devices like smartphones and tablets that can be exposed to sensitive speech, revealing the significance of this potential threat. These studies have amassed significant attention in news and media and introduced concern to people about the safety of their day-to-day speech and around their personal, wireless and IoT devices. However, we hypothesize that the controlled experiments in the prior research maintain critical parameter values that are favorable to attack success (deviating from the limiting settings in a real-world scenario) and produce results that suggest a greater real-life threat level than actually exists.The contributions made in this paper are as follows; First, we provide a detailed review of 10 existing academic research works related to vibration-based eavesdropping attacks. Second, we identify key experimental parameters that can impact the success of eavesdropping in the vibration domain. Third, we build a framework to evaluate the existing literature based on the Percent Parameters in Favored Settings (PPFS) Score metric that we define. Lastly, we use our defined framework to evaluate the feasibility of the existing vibration-based speech attacks to compromise live human speech to the extent of full speech recognition. The results of our evaluation suggest that none of the existing vibration-based eavesdropping attacks have a high likelihood of successfully compromising live human speech in a real-world scenario.},
  booktitle = {Proceedings of the 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
  pages     = {273–287},
  numpages  = {15},
  keywords  = {vibration, speech eavesdropping, side-channel, SoK},
  location  = {Abu Dhabi, United Arab Emirates},
  series    = {WiSec '21}
}

@misc{EveGuard2024,
  title         = {EveGuard: Defeating Vibration-based Side-Channel Eavesdropping with Audio Adversarial Perturbations},
  author        = {Jung-Woo Chang and Ke Sun and David Xia and Xinyu Zhang and Farinaz Koushanfar},
  year          = {2024},
  eprint        = {2411.10034},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/abs/2411.10034}
}

@online{RenishawLidar,
  title        = {Optical encoders and LiDAR scanning},
  url          = {https://www.renishaw.com/en/optical-encoders-and-lidar-scanning--39244},
  organization = {Renishaw plc},
  lastaccessed = {January 07, 2025}
}

@online{WikipediaLDV,
  title        = {Laser Doppler vibrometer},
  url          = {https://en.wikipedia.org/wiki/Laser_Doppler_vibrometer#/media/File:LDV_Schematic.png},
  year         = {2024},
  organization = {Wikipedia},
  lastaccessed = {January 07, 2025}
}

@online{DPAMicrophonesFactsAboutSpeechIntelligibility,
  title        = {Facts about speech intelligibility},
  url          = {https://www.dpamicrophones.com/mic-university/background-knowledge/facts-about-speech-intelligibility/},
  organization = {DPA Microphones A/S},
  author       = {Eddy Bøgh Brixen},
  lastaccessed = {January 07, 2025}
}

@online{BitdefenderRobotVacuumEavesdrop,
  title        = {Robot vacuum cleaners can eavesdrop on your conversations, researchers reveal},
  author       = {Graham CLULEY},
  organization = {Bitdefender},
  url          = {https://www.bitdefender.com/en-us/blog/hotforsecurity/robot-vacuum-cleaners-can-eavesdrop-conversations-researchers-reveal},
  year         = {2020},
  lastaccessed = {January 07, 2025}
}

@online{ForbesRobotVacuumEavesdrop,
  title        = {Hacked Vacuum Cleaner Can Record Your Conversations—No Microphone Required},
  author       = {Davey Winder},
  organization = {Forbes},
  year         = {2020},
  url          = {https://www.forbes.com/sites/daveywinder/2020/11/22/how-this-hacked-vacuum-cleaner-can-listen-to-your-conversations-using-lidar},
  lastaccessed = {January 07, 2025}
}

@online{AndroidDeveloperSensorDocs,
  title        = {Sensors Overview},
  organization = {Android Developers},
  year         = {2024},
  url          = {https://developer.android.com/develop/sensors-and-location/sensors/sensors_overview#sensors-rate-limiting},
  lastaccessed = {January 07, 2025}
}

@online{AppleDeveloperAccelerometerData,
  title        = {Getting raw accelerometer events},
  organization = {Apple Developer},
  url          = {https://developer.apple.com/documentation/coremotion/getting-raw-accelerometer-events},
  year         = {2024},
  lastaccessed = {January 07, 2025}
}

@online{AppleDeveloperGyroscopeData,
  title        = {Getting raw gyroscope events},
  organization = {Apple Developer},
  url          = {https://developer.apple.com/documentation/coremotion/getting-raw-gyroscope-events},
  year         = {2024},
  lastaccessed = {January 07, 2025}
}

@online{MDNWebDocsSensorAPI,
  title        = {Sensor APIs},
  organization = {MDN Web Docs},
  url          = {https://developer.mozilla.org/en-US/docs/Web/API/Sensor_APIs},
  lastaccessed = {January 07, 2025}
}

@online{W3CAccelerometerQuantization,
  title        = {Accelerometer},
  organization = {W3C},
  author       = {Editor's Draft},
  year         = {2024},
  url          = {https://w3c.github.io/accelerometer/#accelerometer-reading-quantization-algorithm},
  lastaccessed = {January 07, 2025}
}

@online{AppleDeveloperMotionUsageDescription,
  title        = {NSMotionUsageDescription},
  organization = {Apple Developer},
  url          = {https://developer.apple.com/documentation/BundleResources/Information-Property-List/NSMotionUsageDescription},
  lastaccessed = {January 07, 2025}
}

@online{WaymoDriver,
  title        = {Waymo Driver},
  organization = {Waymo LLC},
  url          = {https://waymo.com/waymo-driver/},
  lastaccessed = {January 07, 2025}
}

@online{DJIEnterpriseLidar,
  title        = {LiDAR Drone Systems: Using LiDAR Equipped UAVs},
  organization = {DJI},
  author       = {DJI Enterprise},
  year         = {2022},
  url          = {https://enterprise-insights.dji.com/blog/lidar-equipped-uavs},
  lastaccessed = {January 07, 2025}
}

@online{StatcounterOSMarketShare,
  title        = {Mobile Operating System Market Share Worldwide},
  url          = {https://gs.statcounter.com/os-market-share/mobile/worldwide},
  year         = {2024},
  organization = {StatCounter},
  lastaccessed = {January 07, 2025}
}

@online{ElectroboomLighterMicrophone,
  title        = {Microphone in a Lighter, A Piezo Application},
  year         = {2020},
  organization = {ElectroBOOM},
  url          = {https://www.electroboom.com/?p=1156},
  lastaccessed = {January 07, 2025}
}
